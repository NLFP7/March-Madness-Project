#March Madness Project
#I took notes and methods from: https://www.kaggle.com/code/robikscube/2020-march-madness-data-first-look-eda/notebook#Team-Data and https://blog.coast.ai/this-is-how-i-used-machine-learning-to-accurately-predict-villanova-to-win-the-2016-march-madness-ba5c074f1583#.e6xllp64p, thanks to the author
#Note: All datasets are provided by Kaggle March Madness competition, due to the agreenment issue, datasets will not be provided in this case.
#Set ups
import pandas as pd
import numpy as np
import matplotlib.pylab as plt
import matplotlib as mpl
from matplotlib.patches import Circle, Rectangle, Arc
import seaborn as sns
plt.style.use('seaborn-dark-palette')
mypal = plt.rcParams['axes.prop_cycle'].by_key()['color'] # Grab the color pal
import os
import gc


MENS_DIR = '../input/google-cloud-ncaa-march-madness-2020-division-1-mens-tournament'
WOMENS_DIR = '../input/google-cloud-ncaa-march-madness-2020-division-1-womens-tournament'

#Data Imports

Mss = pd.read_csv(f'{MENS_DIR}/MSampleSubmissionStage1_2020.csv')
Wss = pd.read_csv(f'{WOMENS_DIR}/WSampleSubmissionStage1_2020.csv')
Mss.head()

a = pd.read_csv(f'{MENS_DIR}/MDataFiles_Stage1/MSecondaryTourneyCompactResults.csv')
a.head(10)

#EDA
##Team Data
###Since First D1 Season represents the first season which the team joined the division 1, so welcome to D1 league Merrimack!

Mteams = pd.read_csv(f'{MENS_DIR}/MDataFiles_Stage1/MTeams.csv')
Mteams.sort_values('FirstD1Season', ascending = False).head(10)

##Season Data
###RegionW vs RegionX: Since regionW and regionX are in the same side, so we are interested of its historical matchups, and as we can see, East vs Midwest is the most common matchup betweens W and X regions. It objectly reflects the level of these two areas.

Mseasons = pd.read_csv(f'{MENS_DIR}/MDataFiles_Stage1/MSeasons.csv')
Mseasons.head(5)

WandX = Mseasons.groupby(['RegionW', 'RegionX']).size()
countWX = WandX.reset_index(name='WX')
sortWX = countWX.sort_values('WX', ascending = False)
sortWX.head(10)

###RegionY vs RegionZ: Since regionY and regionZ are in the same side, so we are interested of its historical matchups as well, and as we can see, Midwest vs West is the most common matchup betweens Y and Z regions. And it has 12 matchups in the past which is significantly higher than any other region matchups.

YandZ = Mseasons.groupby(['RegionY', 'RegionZ']).size()
countYZ = YandZ.reset_index(name='YZ')
sortYZ = countYZ.sort_values('YZ', ascending = False)
sortYZ.head(10)

#Tourney Seed Data

MTourneySeed = pd.read_csv(f'{MENS_DIR}/MDataFiles_Stage1/MNCAATourneySeeds.csv')
MTourneySeed.head(10)

Wseed1 = MTourneySeed[MTourneySeed['Seed'] == 'W01'].groupby('TeamID').count().reset_index()
Wseed1.sort_values('Seed', ascending = False)

Zseed1 = MTourneySeed[MTourneySeed['Seed'] == 'Z01'].groupby('TeamID').count().reset_index()
Zseed1.sort_values('Seed', ascending = False)

print(Mteams[Mteams['TeamID'] == 1112])
print(Mteams[Mteams['TeamID'] == 1163])

#Tourney Data

MTourneyCompactResult = pd.read_csv(f'{MENS_DIR}/MDataFiles_Stage1/MNCAATourneyCompactResults.csv')
MTourneyCompactResult.head(5)

MTourneyCompactResult = \
    MTourneyCompactResult \
    .merge(Mteams[['TeamName', 'TeamID']],
          left_on = 'WTeamID',
          right_on = 'TeamID',
          validate = 'many_to_one') \
    .drop('TeamID', axis = 1) \
    .rename(columns = {'TeamName':'WTeamName'}) \
    .merge(Mteams[['TeamName', 'TeamID']],
          left_on = 'LTeamID',
          right_on = 'TeamID',) \
    .drop('TeamID', axis = 1) \
    .rename(columns = {'TeamName': 'LTeamName'})

MTourneyCompactResult.head(5)

MTourneyCompactResult['ScoreDiff'] = MTourneyCompactResult['WScore'] - MTourneyCompactResult['LScore']
MTourneyCompactResult.head(5)

plt.style.use('fivethirtyeight')
MTourneyCompactResult['ScoreDiff'] \
    .plot(kind = 'hist',
          bins = 90,
          figsize = (15, 5),
          label = 'mens',
          alpha = 0.5)
plt.xlabel('Scores')
plt.ylabel('Occured Times')

plt.style.use('fivethirtyeight')
fig, axs = plt.subplots(1,2, figsize = (15, 5))
MTourneyCompactResult['counter'] = 1
MTourneyCompactResult.groupby('WTeamName')['counter'] \
    .count() \
    .sort_values() \
    .tail(20) \
    .plot(kind = 'barh',
          title = 'Most Tourney Wins Teams',
          figsize = (15,8),
          xlim = (0,200),
          color = mypal[2],
          ax = axs[0])
MTourneyCompactResult.groupby('WTeamName')['counter'] \
    .count() \
    .sort_values(ascending = False) \
    .tail(20) \
    .plot(kind = 'barh',
          title = 'Least Tourney Wins Wins Teams',
          figsize = (15, 8),
          xlim = (0, 5),
          color = mypal[0],
          ax = axs[1])
plt.tight_layout()
plt.show()

#Regular Season Data

MRegularSeasonCompactResult = pd.read_csv(f'{MENS_DIR}/MDataFiles_Stage1/MRegularSeasonCompactResults.csv')
MRegularSeasonCompactResult.head(5)

MRegularSeasonCompactResult = \
    MRegularSeasonCompactResult \
    .merge(Mteams[['TeamName', 'TeamID']],
          left_on = 'WTeamID',
          right_on = 'TeamID',
          validate = 'many_to_one') \
    .drop('TeamID', axis = 1) \
    .rename(columns = {'TeamName':'WTeamName'}) \
    .merge(Mteams[['TeamName', 'TeamID']],
          left_on = 'LTeamID',
          right_on = 'TeamID',) \
    .drop('TeamID', axis = 1) \
    .rename(columns = {'TeamName': 'LTeamName'})

MRegularSeasonCompactResult.head(5)

MRegularSeasonCompactResult['ScoreDiff'] = MRegularSeasonCompactResult['WScore'] - MRegularSeasonCompactResult['LScore']
MRegularSeasonCompactResult.head(5)

plt.style.use('fivethirtyeight')
MRegularSeasonCompactResult['ScoreDiff'] \
    .plot(kind = 'hist',
          bins = 90,
          figsize = (15, 5),
          label = 'mens',
          alpha = 0.5)
plt.xlabel('Scores')
plt.ylabel('Occured Times')

plt.style.use('fivethirtyeight')
fig, axs = plt.subplots(1,2, figsize = (15, 5))
MRegularSeasonCompactResult['counter'] = 1
MRegularSeasonCompactResult.groupby('WTeamName')['counter'] \
    .count() \
    .sort_values() \
    .tail(20) \
    .plot(kind = 'barh',
          title = 'Most Regular Season Wins Teams',
          figsize = (15,8),
          xlim = (600, 920),
          color = mypal[2],
          ax = axs[0])
MRegularSeasonCompactResult.groupby('WTeamName')['counter'] \
    .count() \
    .sort_values(ascending = False) \
    .tail(20) \
    .plot(kind = 'barh',
          title = 'Least Regular Season Wins Teams',
          figsize = (15, 8),
          xlim = (0, 150),
          color = mypal[0],
          ax = axs[1])
plt.tight_layout()
plt.show()

#Modeling Process

import math
from sklearn import linear_model
from sklearn.model_selection import cross_val_score
import csv
import random

base_elo = 1600
team_elos = {}  # Reset each year.
team_stats = {}
X = []
y = []
submission_data = []
prediction_year = 2020

def initialize_data():
    for i in range(1985, prediction_year+1):
        team_elos[i] = {}
        team_stats[i] = {}


def get_elo(season, team):
    try:
        return team_elos[season][team]
    except:
        try:
            # Get the previous season's ending value.
            team_elos[season][team] = team_elos[season-1][team]
            return team_elos[season][team]
        except:
            # Get the starter elo.
            team_elos[season][team] = base_elo
            return team_elos[season][team]

def calc_elo(win_team, lose_team, season):
    winner_rank = get_elo(season, win_team)
    loser_rank = get_elo(season, lose_team)

    """
    This is originally from from:
    http://zurb.com/forrst/posts/An_Elo_Rating_function_in_Python_written_for_foo-hQl
    """
    rank_diff = winner_rank - loser_rank
    exp = (rank_diff * -1) / 400
    odds = 1 / (1 + math.pow(10, exp))
    if winner_rank < 2100:
        k = 32
    elif winner_rank >= 2100 and winner_rank < 2400:
        k = 24
    else:
        k = 16
    new_winner_rank = round(winner_rank + (k * (1 - odds)))
    new_rank_diff = new_winner_rank - winner_rank
    new_loser_rank = loser_rank - new_rank_diff

    return new_winner_rank, new_loser_rank

def predict_winner(team_1, team_2, model, season, stat_fields):
    features = []

    # Team 1
    features.append(get_elo(season, team_1))
    for stat in stat_fields:
        features.append(get_stat(season, team_1, stat))

    # Team 2
    features.append(get_elo(season, team_2))
    for stat in stat_fields:
        features.append(get_stat(season, team_2, stat))

    return model.predict_proba([features])

def update_stats(season, team, fields):
    """
    This accepts some stats for a team and udpates the averages.

    First, we check if the team is in the dict yet. If it's not, we add it.
    Then, we try to check if the key has more than 5 values in it.
        If it does, we remove the first one
        Either way, we append the new one.
    If we can't check, then it doesn't exist, so we just add this.

    Later, we'll get the average of these items.
    """
    if team not in team_stats[season]:
        team_stats[season][team] = {}

    for key, value in fields.items():
        # Make sure we have the field.
        if key not in team_stats[season][team]:
            team_stats[season][team][key] = []

        if len(team_stats[season][team][key]) >= 9:
            team_stats[season][team][key].pop()
        team_stats[season][team][key].append(value)


def get_stat(season, team, field):
    try:
        l = team_stats[season][team][field]
        return sum(l) / float(len(l))
    except:
        return 0

def build_team_dict():
    team_ids = pd.read_csv(f'{MENS_DIR}/MDataFiles_Stage1/MTeams.csv')
    team_id_map = {}
    for index, row in team_ids.iterrows():
        team_id_map[row['TeamID']] = row['TeamName']
    return team_id_map

def build_season_data(all_data):
    # Calculate the elo for every game for every team, each season.
    # Store the elo per season so we can retrieve their end elo
    # later in order to predict the tournaments without having to
    # inject the prediction into this loop.
    print("Building season data.")
    for index, row in all_data.iterrows():
        # Used to skip matchups where we don't have usable stats yet.
        skip = 0

        # Get starter or previous elos.
        team_1_elo = get_elo(row['Season'], row['WTeamID'])
        team_2_elo = get_elo(row['Season'], row['LTeamID'])

        # Add 100 to the home team (# taken from Nate Silver analysis.)
        if row['WLoc'] == 'H':
            team_1_elo += 100
        elif row['WLoc'] == 'A':
            team_2_elo += 100

        # We'll create some arrays to use later.
        team_1_features = [team_1_elo]
        team_2_features = [team_2_elo]

        # Build arrays out of the stats we're tracking..
        for field in stat_fields:
            team_1_stat = get_stat(row['Season'], row['WTeamID'], field)
            team_2_stat = get_stat(row['Season'], row['LTeamID'], field)
            if team_1_stat != 0 and team_2_stat != 0:
                team_1_features.append(team_1_stat)
                team_2_features.append(team_2_stat)
            else:
                skip = 1

        if skip == 0:  # Make sure we have stats.
            # Randomly select left and right and 0 or 1 so we can train
            # for multiple classes.
            if random.random() > 0.5:
                X.append(team_1_features + team_2_features)
                y.append(0)
            else:
                X.append(team_2_features + team_1_features)
                y.append(1)

        # AFTER we add the current stuff to the prediction, update for
        # next time. Order here is key so we don't fit on data from the
        # same game we're trying to predict.
        if row['WFTA'] != 0 and row['LFTA'] != 0:
            stat_1_fields = {
                'score': row['WScore'],
                'fgp': row['WFGM'] / row['WFGA'] * 100,
                'fga': row['WFGA'],
                'fga3': row['WFGA3'],
                '3pp': row['WFGM3'] / row['WFGA3'] * 100,
                'ftp': row['WFTM'] / row['WFTA'] * 100,
                'or': row['WOR'],
                'dr': row['WDR'],
                'ast': row['WAst'],
                'to': row['WTO'],
                'stl': row['WStl'],
                'blk': row['WBlk'],
                'pf': row['WPF']
            }
            stat_2_fields = {
                'score': row['LScore'],
                'fgp': row['LFGM'] / row['LFGA'] * 100,
                'fga': row['LFGA'],
                'fga3': row['LFGA3'],
                '3pp': row['LFGM3'] / row['LFGA3'] * 100,
                'ftp': row['LFTM'] / row['LFTA'] * 100,
                'or': row['LOR'],
                'dr': row['LDR'],
                'ast': row['LAst'],
                'to': row['LTO'],
                'stl': row['LStl'],
                'blk': row['LBlk'],
                'pf': row['LPF']
            }
            update_stats(row['Season'], row['WTeamID'], stat_1_fields)
            update_stats(row['Season'], row['LTeamID'], stat_2_fields)

        # Now that we've added them, calc the new elo.
        new_winner_rank, new_loser_rank = calc_elo(
            row['WTeamID'], row['LTeamID'], row['Season'])
        team_elos[row['Season']][row['WTeamID']] = new_winner_rank
        team_elos[row['Season']][row['LTeamID']] = new_loser_rank

    return X, y

if __name__ == "__main__":
    stat_fields = ['score', 'fga', 'fgp', 'fga3', '3pp', 'ftp', 'or', 'dr',
                   'ast', 'to', 'stl', 'blk', 'pf']

    initialize_data()
    season_data = pd.read_csv(f'{MENS_DIR}/MDataFiles_Stage1/MRegularSeasonDetailedResults.csv')
    tourney_data = pd.read_csv(f'{MENS_DIR}/MDataFiles_Stage1/MNCAATourneyDetailedResults.csv')
    frames = [season_data, tourney_data]
    all_data = pd.concat(frames)

    # Build the working data.
    X, y = build_season_data(all_data)

    # Fit the model.
    print("Fitting on %d samples." % len(X))

    model = linear_model.LogisticRegression(max_iter = 200)

    # Check accuracy.
    print("Doing cross-validation.")
    print(cross_val_score(
        model, np.array(X), np.array(y), cv=10, scoring='accuracy', n_jobs=-1
    ).mean())

    model.fit(X, y)
